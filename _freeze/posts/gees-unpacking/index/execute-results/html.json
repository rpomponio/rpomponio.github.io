{
  "hash": "6cc785dc5c203aca0b7f25f9446bc85a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"What the heck are GEEs Doing?\"\nauthor: \"Ray Pomponio\"\ndate: today\ncategories: [statistics, analysis]\ndraft: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n\nFollowing along with an online stats course example,[^1] I began to unpack GEEs and understand what they're doing. The data in this example come from a survey in which respondents were asked to rank their confidence in educational, medical, and scientific institutions. Each respondent had three observations in the dataset:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss <- fread(\"gss.confidence.csv\")\ndim(gss)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4401    6\n```\n\n\n:::\n:::\n\n\n\nAltogether there were 1467 respondents.\n\nLet's treat each observation as independent, which is a bad assumption. However I will show why that's a bad idea shortly. For now, we can easily fit a model with a binary outcome and an arbitrary set of predictors using the `glm()` function:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngss[, agedec:=age / 10]\nfit.glm <- glm(greatly ~ question + agedec, data=gss, family=binomial)\ntidy(fit.glm, exponentiate=TRUE, conf.int=TRUE) |>\n  knitr::kable(digits=2)\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:----------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)      |     0.43|      0.11|     -8.09|    0.00|     0.35|      0.52|\n|questionconmedic |     1.65|      0.08|      6.20|    0.00|     1.41|      1.94|\n|questionconsci   |     2.46|      0.08|     11.28|    0.00|     2.11|      2.88|\n|agedec           |     0.95|      0.02|     -2.70|    0.01|     0.92|      0.99|\n\n\n:::\n:::\n\n\nThe model suggests with a high degree of precision that both medical institutions and scientific institutions are *more* likely to be rated favorably by respondents, and that older respondents are *less* likely to rate any institutions favorably.\n\nHowever, this might be a bad model because, as we know, each respondent answered three questions and the answers within a single respondent are likely to be correlated. The directional effect of this correlation on resulting estimates is difficult to determine, but statistical theory suggests that our current estimates may be biased.\n\nBelow I attempt to visualize the observed correlation structure, to show that answers from the same respondent are indeed correlated:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n[Notice that I've left out elements from the lower triangle but they are identical to the upper triangle in any correlatin matrix, by design.]{.aside}\n\nThe respondents' answers are positively correlated, with stronger correlation between questions on medicine and education and between questions on medicine and science (makes sense). They are also correlated between the questions on education and science, just not as strongly.\n\nNow let's move away from assuming independence and instead use GEEs with an **exchangeable** correlation structure. This structure states that the off-diagonal elements of the correlation matrix are constant in magnitude:\n\n$$\n\\begin{bmatrix}\n1 & \\rho & \\rho \\\\\n- & 1 & \\rho \\\\\n- & - & 1\n\\end{bmatrix}\n$$\nSo we fit this structure with GEEs and examine the new estimates, compared to our old ones:\n\n::: {.panel-tabset}\n\n## GEE\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# gee with exchangeable corr structure; avoid overdispersion with scale.fix=T\nfit.exch <- geeglm(greatly ~ question + agedec, data=gss, family=binomial,\n                   id=id, corstr=\"exchangeable\", scale.fix=TRUE)\ntidy(fit.exch, exponentiate=TRUE, conf.int=TRUE) |>\n  knitr::kable(digits=2)\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:----------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)      |     0.43|      0.12|     47.31|    0.00|     0.34|      0.55|\n|questionconmedic |     1.65|      0.07|     51.95|    0.00|     1.44|      1.90|\n|questionconsci   |     2.46|      0.07|    149.06|    0.00|     2.13|      2.85|\n|agedec           |     0.95|      0.02|      4.91|    0.03|     0.91|      0.99|\n\n\n:::\n:::\n\n\n## GLM\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy(fit.glm, exponentiate=TRUE, conf.int=TRUE) |>\n  knitr::kable(digits=2)\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:----------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)      |     0.43|      0.11|     -8.09|    0.00|     0.35|      0.52|\n|questionconmedic |     1.65|      0.08|      6.20|    0.00|     1.41|      1.94|\n|questionconsci   |     2.46|      0.08|     11.28|    0.00|     2.11|      2.88|\n|agedec           |     0.95|      0.02|     -2.70|    0.01|     0.92|      0.99|\n\n\n:::\n:::\n\n\n\n:::\n\nNotice there's no difference in the estimated coefficients, but the standard errors changed, causing the resulting inference to change (p-values and confidence intervals).\n\nWhat's confusing is that the direction of change is not the same across the coefficients, as you can see by flipping back and forth between the \"GEE\" tab and the \"GLM\" tab. By accounting for correlation among respondents' answers, we lost some precision in the intercept estimate, yet gained precision in the estimates of the fixed effects for question category.\n\nYou might be wondering what the model estimated for the correlation parameter, $\\rho$. That also comes with a standard error:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(fit.exch)$corr |>\n  knitr::kable(digits=3)\n```\n\n::: {.cell-output-display}\n\n\n|      | Estimate| Std.err|\n|:-----|--------:|-------:|\n|alpha |    0.233|   0.017|\n\n\n:::\n:::\n\n\n\nThis estimate makes sense, because it's sort-of-an-average over the three correlation values we obtained earlier (0.26, 0.29, and 0.15).\n\nLastly I wanted to assess the potential impact of specifying a different correlation structure, such as **unstructured** correlation, which is arguably appropriate for these data since pairs of questions were not uniformly correlated.\n\n::: {.panel-tabset}\n\n## Unstructured\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# gee with unstructured corr structure; avoid overdispersion with scale.fix=T\nfit.unst <- geeglm(greatly ~ question + agedec, data=gss, family=binomial,\n                   id=id, corstr=\"unstructured\", scale.fix=TRUE)\ntidy(fit.unst, exponentiate=TRUE, conf.int=TRUE) |>\n  knitr::kable(digits=2)\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:----------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)      |     0.43|      0.12|     47.76|    0.00|     0.34|      0.54|\n|questionconmedic |     1.65|      0.07|     51.93|    0.00|     1.44|      1.90|\n|questionconsci   |     2.46|      0.07|    149.07|    0.00|     2.13|      2.85|\n|agedec           |     0.95|      0.02|      4.78|    0.03|     0.91|      0.99|\n\n\n:::\n:::\n\n\n\n## Exchangeable\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ntidy(fit.exch, exponentiate=TRUE, conf.int=TRUE) |>\n  knitr::kable(digits=2)\n```\n\n::: {.cell-output-display}\n\n\n|term             | estimate| std.error| statistic| p.value| conf.low| conf.high|\n|:----------------|--------:|---------:|---------:|-------:|--------:|---------:|\n|(Intercept)      |     0.43|      0.12|     47.31|    0.00|     0.34|      0.55|\n|questionconmedic |     1.65|      0.07|     51.95|    0.00|     1.44|      1.90|\n|questionconsci   |     2.46|      0.07|    149.06|    0.00|     2.13|      2.85|\n|agedec           |     0.95|      0.02|      4.91|    0.03|     0.91|      0.99|\n\n\n:::\n:::\n\n\n\n:::\n\nDoesn't seem to make much of a difference.\n\n# Appendix\n\nHere's the estimated correlation structure with the last GEE:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nV.unst <- diag(3)\nV.unst[upper.tri(V.unst)] <- summary(fit.unst)$corr$Estimate\nV.unst[lower.tri(V.unst)] <- summary(fit.unst)$corr$Estimate\nround(V.unst, 3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1]  [,2]  [,3]\n[1,] 1.000 0.263 0.148\n[2,] 0.263 1.000 0.289\n[3,] 0.148 0.289 1.000\n```\n\n\n:::\n:::\n\n\n\n[^1]: Penn State Eberly College of Science. STAT 504: Analysis of Discrete Data. 12.1 - Introduction to Generalized Estimating Equations. <https://online.stat.psu.edu/stat504/lesson/12/12.1>.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}