{
  "hash": "76aeb72b7f4492496c93fd63ade9761e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Rethinking Some Statistical Principles\"\nauthor: \"Ray Pomponio\"\ndate: today\ncategories: [reading, reflections]\n---\n\n\n\nI've begun reading *Statistical Rethinking* by Richard McElreath,[^1] and I want to log some of my thoughts that came to mind while working through his ideas on modern statistical science.\n\n# Chapter 2\n\n## Likelihoods\n\nIn this chapter, a hypothetical experiment was introduced in which an observer collects data about the proportion of water on a globe (to understand the true proportion of water on earth).\n\nLet $p$ denote the proportion of water on the globe, $W$ the number of observations that yielded \"water\", and $L$ the number of observations that yielded \"land\". By the Binomial distribution: \n\n$$\nPr(W=w,L=l\\quad|\\quad p)={w+l\\choose w}p^w(1-p)^l\n$$\n\nNow presume the observer recorded $W=6$ and $L=3$ in nine trials. The \"likelihood\" of these data can be plotted as a function of probability:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n\nAnd this is **by no means a probabiltity distribution**. It doesn't sum to one; it integrates to 0.1. However the recognition of this function is a crucial step towards two possible modes of inference:\n\n* In a **classical** sense, this function represents an objective to maximize, then compare against a null hypothesis (often $H_0: p=0.5$).\n* In a **Bayesian** sense, this function represents one piece of the joint distribution of $W, L, p$ (the other piece being the prior on $p$). And this is the mode of inference advocated by the book.\n\nWhen we start with a uniform prior $p\\sim\\text{Beta}(1, 1)$, we end up with a posterior that looks uncannily like our likelihood function:\n\n:::{.panel-tabset}\n\n\n### Posterior\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n### Likelihood (again)\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\nThey're actually the same function, just with different *y-axis* scales. I previously didn't realize that...\n\n::: {.callout-tip}\n## Likelihoods as Objectives\n\nAs part of the classical mode of inference, one might reasonably seek to maximize the above likelihood function $\\mathcal{L}$, setting $p=\\hat{p}$ at maximal likelihood, then comparing the ratio of likelihoods between $\\mathcal{L}(\\hat{p})$ and $\\mathcal{L}(p_0)$. It turns out, when this ratio is greater than some constant $c$, one would rationally conclude that $p\\neq p_0$ (in other words, one rejects the null hypothesis).\n:::\n\nSo contrasting the two modes of inference: in the classical sense, one compares two points along the likelihood curve to posit evidence against some hypothesis $H_0$. In a Bayesian sense, one obtains a posterior distribution over plausible values of $p$, which can be further analyzed for compatability with any set of hypotheses. And the realization for me (at least in this trivial example) is that the likelihood and posterior functions are the **exact same shape**.\n\nReflecting on this a little more, I can understand how the relative simplicity of the classical approach might be appealing at the start of a scientific inquiry, say, when we don't know much about the phenomenon but expect to learn a lot quickly. However, when an inquiry matures to the point of having data readily available, it seems silly to forgo the benefit of having the entire distribution of a parameter available to interrogate. It's clear that the latter offers a richer description of the unknown phenomenon. Perhaps an analogy would be like entering a dark cavernous tunnel, where the classical approach affords you looks at two possible paths forward (one of which is a dead-end and the other quite a promising lead). The Bayesian approach, on the other hand, affords you something like a map of multiple paths forward.\n\n## Algorithms for Posterior Approximation\n\nI was previously aware of posterior approximation using Markov chain Monte Carlo (MCMC), but I was surprised to learn about two viable alternatives to numerically sampling from a posterior distribution.\n\nI'll continue with the hypothetical experiment from the previous section in which we are aiming to estimate $p$, the proportion of water on the globe.\n\n:::{.panel-tabset}\n\n### Grid Approximation\n\nBy selecting a finite grid across the support of our parameter $p$, we can approximate the posterior:\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ngrid.seq <- seq(0, 1, length.out=20)\nprior <- dunif(grid.seq)\nlikelihood <- dbinom(6, size=9, prob=grid.seq)\nposterior <- prior * likelihood / sum(prior * likelihood)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n### Quadratic Approximation\n\nThis technique involves leveraging a Gaussian approximation of the posterior near its mode. I believe the theory behind it is related to the efficiency property[^2] of MLEs, which states that the MLE converges in distribution to a normal distribution at larger sample sizes. It is relatively easy to code up using the `quap` function from the textbook's `rethinking` package:[^3]\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nposterior <- rethinking::quap(\n  alist(\n    W ~ dbinom(W+L ,p) ,\n    p ~ dunif(0, 1)),\n  data=list(W=6,L=3) )\nquad.post <- rethinking::precis(posterior)\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\n### MCMC\n\nFinally MCMC, which is the most-widely adopted approach to posterior approximation, has many algorithmic variants. The following is an example of the Metropolis Algorithm:[^4]\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nset.seed(1818)\nn.samples <- 2000\np <- rep(NA, n.samples)\np[1] <- 0.5\nobs.data <- list(W=6, L=3)\nfor (i in 2:n.samples){\n  p.new <- rnorm(1 , p[i - 1] , 0.1)\n  if (p.new < 0) p.new <- abs(p.new)\n  if (p.new > 1) p.new <- 2 - p.new\n  q0 <- dbinom(obs.data$W, obs.data$W + obs.data$L, p[i-1])\n  q1 <- dbinom(obs.data$W, obs.data$W + obs.data$L, p.new)\n  p[i] <- ifelse(runif(1) < q1/q0, p.new, p[i-1])\n}\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n:::\n\nThe one intruiging feature of the Metropolis algorithm is the acceptance rule, which computes a ratio of **likelihoods**, given $p$ and $p'$, and accepts the new value $p'$ if this ratio is above some randomly-generated value.\n\nIn other words, the internal mechanics of the algorithm work a bit like the classical approach to inference (see above), in which the likelihoods of two points are compared. In the classical approach, $\\hat{p}$ is never technically \"accepted\", but $p_0$ can be rejected if the ratio of likelihoods ($\\mathcal{L}(\\hat{p})$ vs. $\\mathcal{L}(p_0)$) is above some constant $c$. In contrast to MCMC, however, $c$ is not randomly-generate but instead dictated by the choice of $\\alpha$, which is commonly 0.05.\n\n[^1]: Statistical Rethinking by Richard McElreath. Second Edition. <https://xcelab.net/rm/>.\n[^2]: Efficiency Property of Maximum Likelihood Estimators. <https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Efficiency>.\n[^3]: Rethinking package for R. <https://github.com/rmcelreath/rethinking>.\n[^4]: Metropolis-Hastings Algorithm. <https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm>.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}